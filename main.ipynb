{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "# \"../\" to go back one director\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from Modules.Utils.Imports import *\n",
    "from Modules.Utils.Gradient import Gradient\n",
    "from Modules.Utils.ModelWrapper import ModelWrapper\n",
    "from torch.autograd import Variable\n",
    "import Scripts.FKPP_functions as FKPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA\n",
    "device = torch.device(GetLowestGPU(pick_from=[0]))\n",
    "importlib.reload(FKPP)\n",
    "\n",
    "# \n",
    "def numpy_to_tensor(ndarray):\n",
    "    arr = torch.tensor(ndarray, dtype=torch.float)\n",
    "    arr.requires_grad_(True)\n",
    "    arr = arr.to(device)\n",
    "    return arr\n",
    "\n",
    "def to_torch(x):\n",
    "    return torch.from_numpy(x).float().to(device)\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biologically informed neural network\n",
    "class BINN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # surface fitter\n",
    "        self.surface_fitter = FKPP.SurfaceFitter(K=1.0)\n",
    "        \n",
    "        # equation variables\n",
    "        self.diffusion = FKPP.ScalarDiffusion()\n",
    "        self.growth = FKPP.LogisticGrowth(K=1.0)\n",
    "        \n",
    "        # parameter extrema\n",
    "        self.D_min = self.diffusion.min\n",
    "        self.D_max = self.diffusion.max\n",
    "        self.r_min = self.growth.min\n",
    "        self.r_max = self.growth.max\n",
    "        \n",
    "        # loss weights\n",
    "        self.IC_weight = 1e0\n",
    "        self.surface_weight = 1e0\n",
    "        self.pde_weight = 1e0\n",
    "        self.pde_IC_weight = 0.1\n",
    "        self.D_weight = 1e4\n",
    "        self.r_weight = 1e4\n",
    "        \n",
    "        # number of samples for pde loss\n",
    "        self.num_samples = 1000\n",
    "        \n",
    "        # input meshgrid\n",
    "        x = np.linspace(x_min, x_max, 100)\n",
    "        t = np.linspace(t_min, t_max, 100)\n",
    "        X, T = np.meshgrid(x, t, indexing='ij')\n",
    "        self.inputs_mesh = np.concatenate([X.reshape(-1, 1), \n",
    "                                           T.reshape(-1, 1)], axis=1)\n",
    "        self.inputs_mesh = numpy_to_tensor(self.inputs_mesh)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # cache input batch on forward pass\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        return self.surface_fitter(self.inputs)\n",
    "    \n",
    "    def surface_loss(self, pred, true):\n",
    "        \n",
    "        residual = (pred - true)**2\n",
    "        \n",
    "        # add weight to initial condition\n",
    "        residual = residual*torch.where(self.inputs[:, 1][:, None]==0,\n",
    "                                self.IC_weight*torch.ones_like(pred), \n",
    "                                torch.ones_like(pred))\n",
    "        \n",
    "        residual = residual*pred.abs().clamp(min=1e-4)**(-gamma)\n",
    "        \n",
    "        return torch.mean(residual)\n",
    "    \n",
    "    def pde_loss(self, inputs, outputs, return_mean=True):\n",
    "        \n",
    "        # unpack inputs\n",
    "        x = inputs[:, 0][:,None]\n",
    "        t = inputs[:, 1][:,None]\n",
    "        \n",
    "        # partial derivative computations \n",
    "        u = outputs.clone()\n",
    "        d1 = Gradient(u, inputs, order=1)\n",
    "        ux = d1[:, 0][:, None]\n",
    "        ut = d1[:, 1][:, None]\n",
    "        \n",
    "        # diffusion\n",
    "        if self.diffusion.inputs == 1:\n",
    "            D = self.diffusion(u)\n",
    "        else:\n",
    "            D = self.diffusion(u, t)\n",
    "            \n",
    "        # growth\n",
    "        if self.growth.inputs == 1:\n",
    "            G = self.growth(u)\n",
    "        else:\n",
    "            G = self.growth(u, t)\n",
    "        \n",
    "        # Fisher-KPP equation\n",
    "        LHS = ut\n",
    "        RHS = Gradient(D*ux, inputs)[:, 0][:,None] + G*u\n",
    "        pde_loss = (LHS-RHS)**2\n",
    "        \n",
    "        return pde_loss\n",
    "    \n",
    "    def parameter_loss(self, inputs, outputs):\n",
    "        \n",
    "        # unpack inputs\n",
    "        x = inputs[:, 0][:,None]\n",
    "        t = inputs[:, 1][:,None]\n",
    "        \n",
    "        # partial derivative computations \n",
    "        u = outputs\n",
    "        d1 = Gradient(u, inputs, order=1)\n",
    "        ux = d1[:, 0][:, None]\n",
    "        ut = d1[:, 1][:, None]\n",
    "        \n",
    "        # diffusion\n",
    "        if self.diffusion.inputs == 1:\n",
    "            D = self.diffusion(u)\n",
    "        else:\n",
    "            D = self.diffusion(u, t)\n",
    "            \n",
    "        # growth\n",
    "        if self.growth.inputs == 1:\n",
    "            G = self.growth(u)\n",
    "        else:\n",
    "            G = self.growth(u, t)\n",
    "        \n",
    "        # constraints on learned parameters\n",
    "        try:\n",
    "            r = self.growth.r\n",
    "        except:\n",
    "            r = G\n",
    "        self.D_loss = 0\n",
    "        self.r_loss = 0\n",
    "        self.s_loss = 0\n",
    "        self.D_loss = self.D_loss + self.D_weight*torch.where(\n",
    "            D < self.D_min, (D-self.D_min)**2, torch.zeros_like(D))\n",
    "        self.D_loss = self.D_loss + self.D_weight*torch.where(\n",
    "            D > self.D_max, (D-self.D_max)**2, torch.zeros_like(D))\n",
    "        self.r_loss = self.r_loss + self.r_weight*torch.where(\n",
    "            r < self.r_min, (r-self.r_min)**2, torch.zeros_like(r))\n",
    "        self.r_loss = self.r_loss + self.r_weight*torch.where(\n",
    "            r > self.r_max, (r-self.r_max)**2, torch.zeros_like(r))\n",
    "        \n",
    "        return torch.sum(self.D_loss + self.r_loss)\n",
    "    \n",
    "    def parameter_loss_PCGrad(self, pred, true):\n",
    "        \n",
    "        self.parameter_loss_val = 0\n",
    "        \n",
    "        # load cached inputs from forward pass\n",
    "        inputs = self.inputs\n",
    "        \n",
    "        # load cached inputs from forward pass\n",
    "        inputs = self.inputs\n",
    "        ######################################################################\n",
    "        # randomly sample from input domain\n",
    "        x = torch.rand(self.num_samples, 1, requires_grad=True) \n",
    "        x = x*(x_max - x_min) + x_min\n",
    "        t = torch.rand(self.num_samples, 1, requires_grad=True)\n",
    "        t = t*(t_max - t_min) + t_min\n",
    "        inputs_rand = torch.cat([x, t], dim=1).float().to(device)\n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "        # predict surface fitter at sampled points\n",
    "        outputs_rand = self.surface_fitter(inputs_rand)\n",
    "        \n",
    "        # compute PDE loss at sampled locations\n",
    "        self.parameter_loss_val = self.pde_weight*self.parameter_loss(inputs_rand, outputs_rand)\n",
    "        \n",
    "        return torch.sum(self.parameter_loss_val)\n",
    "        \n",
    "    def pde_loss_PCGrad(self, pred, true):\n",
    "        \n",
    "        self.pde_loss_val = 0\n",
    "        \n",
    "        # load cached inputs from forward pass\n",
    "        inputs = self.inputs\n",
    "        \n",
    "        # load cached inputs from forward pass\n",
    "        inputs = self.inputs\n",
    "        ######################################################################\n",
    "        # randomly sample from input domain\n",
    "        x = torch.rand(self.num_samples, 1, requires_grad=True) \n",
    "        x = x*(x_max - x_min) + x_min\n",
    "        t = torch.rand(self.num_samples, 1, requires_grad=True)\n",
    "        t = t*(t_max - t_min) + t_min\n",
    "        inputs_rand = torch.cat([x, t], dim=1).float().to(device)\n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "        # predict surface fitter at sampled points\n",
    "        outputs_rand = self.surface_fitter(inputs_rand)\n",
    "        \n",
    "        # compute PDE loss at sampled locations\n",
    "        self.pde_loss_val = self.pde_weight*self.pde_loss(inputs_rand, outputs_rand)\n",
    "        \n",
    "        return torch.sum(self.pde_loss_val)\n",
    "        \n",
    "    def pde_IC_loss_PCGrad(self, pred, true):\n",
    "    \n",
    "        self.IC_loss_val = 0\n",
    "        \n",
    "        # load cached inputs from forward pass\n",
    "        inputs = self.inputs\n",
    "\n",
    "        \n",
    "        ######################################################################\n",
    "        # randomly sample from input domain for x at initial condition\n",
    "        x_IC = torch.rand(self.num_samples, 1, requires_grad=True) \n",
    "        x_IC = x_IC*(x_max - x_min) + x_min\n",
    "        # compute PDE loss at IC data\n",
    "        t_IC = t_min*torch.ones(self.num_samples,1)\n",
    "        inputs_rand_IC = torch.cat([x_IC, t_IC], dim=1).float().to(device)\n",
    "        outputs_rand_IC = self.surface_fitter(inputs_rand_IC)\n",
    "        self.pde_IC_loss_val = self.pde_IC_weight*self.pde_loss(inputs_rand_IC, outputs_rand_IC)\n",
    "        ######################################################################\n",
    "        \n",
    "        return torch.sum(self.pde_IC_loss_val)\n",
    "        \n",
    "    def loss(self, pred, true):\n",
    "        \n",
    "        self.surface_loss_val = 0\n",
    "        self.pde_loss_val = 0\n",
    "        \n",
    "        # load cached inputs from forward pass\n",
    "        inputs = self.inputs\n",
    "        ######################################################################\n",
    "        # randomly sample from input domain\n",
    "        x = torch.rand(self.num_samples, 1, requires_grad=True) \n",
    "        x = x*(x_max - x_min) + x_min\n",
    "        t = torch.rand(self.num_samples, 1, requires_grad=True)\n",
    "        t = t*(t_max - t_min) + t_min\n",
    "        inputs_rand = torch.cat([x, t], dim=1).float().to(device)\n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "        # predict surface fitter at sampled points\n",
    "        outputs_rand = self.surface_fitter(inputs_rand)\n",
    "        \n",
    "        # compute surface loss\n",
    "        self.surface_loss_val = self.surface_weight*self.surface_loss(pred, true)\n",
    "        \n",
    "        ######################################################################\n",
    "        # randomly sample from input domain for x at initial condition\n",
    "        x_IC = torch.rand(self.num_samples, 1, requires_grad=True) \n",
    "        x_IC = x_IC*(x_max - x_min) + x_min\n",
    "        # compute PDE loss at IC data\n",
    "        t_IC = t_min*torch.ones(self.num_samples,1)\n",
    "        inputs_rand_IC = torch.cat([x_IC, t_IC], dim=1).float().to(device)\n",
    "        outputs_rand_IC = self.surface_fitter(inputs_rand_IC)\n",
    "        self.pde_loss_val = self.pde_IC_weight*self.pde_loss(inputs_rand_IC, outputs_rand_IC)\n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "    \n",
    "        # compute PDE loss at sampled locations\n",
    "        self.pde_loss_val = self.pde_loss_val + self.pde_weight*self.pde_loss(inputs_rand, outputs_rand)\n",
    "        \n",
    "        return torch.sum(self.surface_loss_val) + torch.sum(self.pde_loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "path = cur_dir+'/Data'\n",
    "epochs = int(1e6)\n",
    "batch_size = 10\n",
    "rel_save_thresh = 0.01\n",
    "early_stopping = 2000\n",
    "use_PCGrad = False\n",
    "\n",
    "start_patient = 5\n",
    "N_patients = 5\n",
    "star_run = 8 #R14 + 1\n",
    "num_run = 14\n",
    "\n",
    "file_names = ['']*N_patients\n",
    "\n",
    "\n",
    "for i_patient in range(start_patient-1,N_patients):\n",
    "    if i_patient < 9:\n",
    "        file_names[i_patient] = 'patient'+'0'+str(i_patient+1)+'_N10.npy'\n",
    "    else:\n",
    "        file_names[i_patient] = 'patient'+str(i_patient+1)+'_N10.npy'\n",
    "\n",
    "for i_run in range(star_run-1,num_run):\n",
    "    for i_patient in range(start_patient-1,N_patients):\n",
    "\n",
    "        # load data\n",
    "        file_name = file_names[i_patient]\n",
    "        print(file_name)\n",
    "        data = np.load(path +'/'+ file_name, allow_pickle=True).item()\n",
    "\n",
    "        x = data['x'].copy()\n",
    "        t = data['t'].copy()\n",
    "        U = data['U'].copy().T\n",
    "        gamma = data['gamma']\n",
    "        shape = U.shape\n",
    "        D = data['D']\n",
    "        r = data['r']\n",
    "        K = 1\n",
    "        metast_index = data['metast_index']\n",
    "\n",
    "        # compute extrema\n",
    "        x_min, x_max = np.min(x), np.max(x)\n",
    "        t_min, t_max = np.min(t), np.max(t)\n",
    "        u_min, u_max = np.min(U), np.max(U)\n",
    "\n",
    "        # convert to 2D\n",
    "        X, T = np.meshgrid(x, t, indexing='ij')\n",
    "\n",
    "        # prepare for surface fit\n",
    "        inputs = np.concatenate([X.reshape(-1)[:, None],\n",
    "                                 T.reshape(-1)[:, None]], axis=1)\n",
    "        outputs = U.reshape(-1)[:, None]\n",
    "\n",
    "\n",
    "        # split into train/val\n",
    "        N = len(outputs)\n",
    "        split = int(0.8*N)\n",
    "\n",
    "        # Shuffle the list 1 to N\n",
    "        p = np.random.permutation(N)\n",
    "        x_train = inputs[p[:split]]\n",
    "        y_train = outputs[p[:split]]\n",
    "        x_val = inputs[p[split:]]\n",
    "        y_val = outputs[p[split:]]\n",
    "\n",
    "        # convert to pytorch\n",
    "        x_train = numpy_to_tensor(x_train)\n",
    "        y_train = numpy_to_tensor(y_train)\n",
    "        x_val = numpy_to_tensor(x_val)\n",
    "        y_val = numpy_to_tensor(y_val)\n",
    "        inputs = numpy_to_tensor(inputs)\n",
    "        outputs = numpy_to_tensor(outputs)\n",
    "\n",
    "        # Initialize BINN\n",
    "        binn = BINN()\n",
    "        binn.to(device)\n",
    "\n",
    "        weights_dir = cur_dir+'/Weights'\n",
    "        if not os.path.exists(weights_dir):\n",
    "                os.makedirs(weights_dir)\n",
    "        \n",
    "        # compile \n",
    "        parameters = binn.parameters()\n",
    "        opt = torch.optim.Adam(parameters, lr=1e-3)\n",
    "        model = ModelWrapper(\n",
    "            model=binn,\n",
    "            optimizer=opt,\n",
    "            loss=binn.loss,\n",
    "            regularizer=None,\n",
    "            save_name=weights_dir+'/'+file_name[:-4]+'_R'+str(i_run))\n",
    "\n",
    "        t0 = time.time()\n",
    "        # train jointly\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=None,\n",
    "            verbose=1,\n",
    "            validation_data=[x_val, y_val],\n",
    "            early_stopping=early_stopping,\n",
    "            rel_save_thresh=rel_save_thresh)\n",
    "        training_time = time.time() - t0\n",
    "        #################################################################\n",
    "        #\n",
    "        # Plotting\n",
    "        #\n",
    "        #################################################################\n",
    "        plotting_path = cur_dir+'/Plots/'+file_name[:-4]+'/R'+str(i_run)\n",
    "        if not os.path.exists(plotting_path):\n",
    "                os.makedirs(plotting_path)\n",
    "\n",
    "        u_pred = model.predict(inputs.to(device)).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "        # evaluate surface fitter on mesh\n",
    "        x_mesh = np.linspace(x_min, x_max, 100)\n",
    "        t_mesh = np.linspace(t_min, t_max, 100)\n",
    "        x_mesh, t_mesh = np.meshgrid(x_mesh, t_mesh, indexing='ij')\n",
    "        x_mesh, t_mesh = x_mesh.reshape(-1, 1), t_mesh.reshape(-1, 1)\n",
    "        inputs_mesh = numpy_to_tensor(np.concatenate([x_mesh, t_mesh], 1))\n",
    "        u_mesh = model.predict(inputs_mesh).cpu().detach().numpy()\n",
    "        x_mesh = x_mesh.reshape(100,100)\n",
    "        t_mesh = t_mesh.reshape(100,100)\n",
    "        u_mesh = u_mesh.reshape(100,100)\n",
    "\n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(12,7))\n",
    "        ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "        ax.plot_surface(x_mesh, t_mesh, u_mesh, alpha=0.8, cmap=cm.coolwarm)\n",
    "        ax.scatter(X.reshape(-1), T.reshape(-1), U.reshape(-1), color='k', s=5)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('T')\n",
    "        ax.set_zlabel('U')\n",
    "        plt.savefig(plotting_path+'/learned_surface.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # plot in time\n",
    "        prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "        colors = prop_cycle.by_key()['color']\n",
    "        markers = ['x', 'o', 's', 'd', '^', '1',  'P', 'd', '+', '|']\n",
    "        plt.figure(figsize=(14.6,7))\n",
    "        for i in range(len(X.T)):\n",
    "            plt.plot(x_mesh[:,i], u_mesh[:,int(i/(len(X.T)-1)*99)], '-', c=colors[i])\n",
    "        for i in range(len(X.T)):\n",
    "            plt.plot(X[:,i], U[:,i], marker=markers[i], c=colors[i], linestyle='')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('U')\n",
    "        plt.legend(['t0', 't1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9'])\n",
    "        plt.grid()\n",
    "        plt.savefig(plotting_path+'/UvsX.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        model.load_best_val()\n",
    "        # evaluate surface fitter on mesh\n",
    "        x_mesh = np.linspace(x_min, x_max, 100)\n",
    "        t_mesh = np.linspace(t_min, t_max, 100)\n",
    "        x_mesh, t_mesh = np.meshgrid(x_mesh, t_mesh, indexing='ij')\n",
    "        x_mesh, t_mesh = x_mesh.reshape(-1, 1), t_mesh.reshape(-1, 1)\n",
    "        inputs_mesh = numpy_to_tensor(np.concatenate([x_mesh, t_mesh], 1))\n",
    "        u_mesh = model.predict(inputs_mesh)\n",
    "\n",
    "        # compute derivatives\n",
    "        d1 = Gradient(u_mesh, inputs_mesh, order=1)\n",
    "        d1 = [d1[:, i] for i in range(d1.shape[1])]\n",
    "        d2 = [Gradient(d, inputs_mesh, order=1) for d in d1]\n",
    "        d2 = [d2[i][:, j] for i in range(len(d1)) for j in range(len(d1))]\n",
    "\n",
    "        # extract\n",
    "        u0 = to_numpy(u_mesh).reshape([100, 100])\n",
    "        ux = to_numpy(d1[0]).reshape([100, 100])\n",
    "        ut = to_numpy(d1[1]).reshape([100, 100])\n",
    "        uxx = to_numpy(d2[0]).reshape([100, 100])\n",
    "\n",
    "        # 3d surface plots\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        ax = fig.add_subplot(2, 2, 1, projection='3d')\n",
    "        ax.plot_surface(to_numpy(inputs_mesh[:, 0]).reshape([100, 100]), \n",
    "                        to_numpy(inputs_mesh[:, 1]).reshape([100, 100]), \n",
    "                        u0, cmap=cm.coolwarm, alpha=0.9)\n",
    "        plt.title('u')\n",
    "        ax = fig.add_subplot(2, 2, 2, projection='3d')\n",
    "        ax.plot_surface(to_numpy(inputs_mesh[:, 0]).reshape([100, 100]), \n",
    "                        to_numpy(inputs_mesh[:, 1]).reshape([100, 100]), \n",
    "                        ut, cmap=cm.coolwarm, alpha=0.9)\n",
    "        plt.title('ut')\n",
    "        ax = fig.add_subplot(2, 2, 3, projection='3d')\n",
    "        ax.plot_surface(to_numpy(inputs_mesh[:, 0]).reshape([100, 100]), \n",
    "                        to_numpy(inputs_mesh[:, 1]).reshape([100, 100]), \n",
    "                        ux, cmap=cm.coolwarm, alpha=0.9)\n",
    "        plt.title('ux')\n",
    "        ax = fig.add_subplot(2, 2, 4, projection='3d')\n",
    "        ax.plot_surface(to_numpy(inputs_mesh[:, 0]).reshape([100, 100]), \n",
    "                        to_numpy(inputs_mesh[:, 1]).reshape([100, 100]), \n",
    "                        uxx, cmap=cm.coolwarm, alpha=0.9)\n",
    "        plt.title('uxx')\n",
    "        fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.savefig(plotting_path+'/U_Ut_Ux_Uxx.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "        ############################# Train/Val Error/Improvement #############################\n",
    "\n",
    "        # load training errors\n",
    "        total_train_losses = model.train_loss_list\n",
    "        total_val_losses = model.val_loss_list\n",
    "\n",
    "\n",
    "        # find where errors decreased\n",
    "        train_idx, train_loss, val_idx, val_loss = [], [], [], []\n",
    "        best_train, best_val = 1e12, 1e12\n",
    "        for i in range(len(total_train_losses)-1):\n",
    "            rel_diff = (best_train - total_train_losses[i])\n",
    "            rel_diff /= best_train\n",
    "            if rel_diff > rel_save_thresh:\n",
    "                best_train = total_train_losses[i]\n",
    "                train_idx.append(i)\n",
    "                train_loss.append(best_train)\n",
    "            rel_diff = (best_val - total_val_losses[i])\n",
    "            rel_diff /= best_val\n",
    "            if rel_diff > rel_save_thresh:\n",
    "                best_val = total_val_losses[i]\n",
    "                val_idx.append(i)\n",
    "                val_loss.append(best_val)\n",
    "        idx = np.argmin(val_loss)\n",
    "\n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        plt.semilogy(total_train_losses, 'b')\n",
    "        plt.semilogy(total_val_losses, 'r')\n",
    "        plt.semilogy(val_idx[idx], val_loss[idx], 'ko')\n",
    "        plt.legend(['train mse', 'val mse', 'best val'])\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('MSE')\n",
    "        plt.title('Train/Val errors')\n",
    "        plt.grid()\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        plt.semilogy(train_idx, train_loss, 'b.-')\n",
    "        plt.semilogy(val_idx, val_loss, 'r.-')\n",
    "        plt.legend(['train mse', 'val mse'])\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('MSE')\n",
    "        plt.title('Train/Val improvements')\n",
    "        plt.grid()\n",
    "        plt.savefig(plotting_path+'/Train_Val_Err_Improv.png')\n",
    "        plt.close(fig)    \n",
    "\n",
    "        ############################# Residuals #############################\n",
    "        model.load_best_val()\n",
    "\n",
    "        #\n",
    "        # Residual plots\n",
    "        #\n",
    "\n",
    "        # model prediction\n",
    "        u_pred = model.predict(inputs.to(device)).cpu().detach().numpy().reshape(-1)\n",
    "        u_true = U.reshape(-1)\n",
    "        residuals = u_pred - u_true\n",
    "        modified_residuals = residuals * np.abs(u_pred).clip(1e-4,np.inf)**(-gamma)\n",
    "\n",
    "        # plot modified residuals\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        plt.scatter(u_pred, modified_residuals, color='k', s=10)\n",
    "        plt.plot([np.min(u_pred), np.max(u_pred)], [0, 0], 'k--')\n",
    "        plt.xlabel('U')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.savefig(plotting_path+'/Residuals.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # plot heatmap of residuals\n",
    "        fig = plt.figure(figsize=(11,7))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        res = ax.imshow(U-u_pred.reshape(shape), aspect='auto',vmin=-0.5, vmax=0.5,\n",
    "                        extent=[np.min(t), np.max(t), np.min(x), np.max(x)],)\n",
    "        ax.set_xlabel('T')\n",
    "        ax.set_ylabel('X')\n",
    "        ax.set_title('Surface Residuals')\n",
    "        fig.colorbar(res)\n",
    "        plt.savefig(plotting_path+'/Surface_Residuals.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # evaluate surface fitter on mesh\n",
    "        x_mesh = np.linspace(np.min(x), np.max(x), 100)\n",
    "        t_mesh = np.linspace(np.min(t), np.max(t), 100)\n",
    "        x_mesh, t_mesh = np.meshgrid(x_mesh, t_mesh, indexing='ij')\n",
    "        x_mesh, t_mesh = x_mesh.reshape(-1, 1), t_mesh.reshape(-1, 1)\n",
    "        inputs_mesh = numpy_to_tensor(np.concatenate([x_mesh, t_mesh], 1))\n",
    "        u_mesh = model.predict(inputs_mesh)\n",
    "        pde_losses = binn.pde_loss(inputs_mesh, u_mesh, return_mean=False)\n",
    "        u_mesh = u_mesh.cpu().detach().numpy().reshape(100,100)\n",
    "        pde_losses = pde_losses.cpu().detach().numpy().reshape(100,100)\n",
    "        x_mesh = x_mesh.reshape(100,100)\n",
    "        t_mesh = t_mesh.reshape(100,100)\n",
    "\n",
    "        # plot heatmap of pde losses\n",
    "        fig = plt.figure(figsize=(11,7))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        res = ax.imshow(np.sqrt(pde_losses), aspect='auto', vmin=0, vmax=0.5,\n",
    "                        extent=[np.min(t), np.max(t), np.min(x), np.max(x)],)\n",
    "        ax.set_xlabel('Time (days)')\n",
    "        ax.set_ylabel('Position (mm)')\n",
    "        ax.set_title('PDE Losses, max = {0:1.4e}'.format(np.max(np.sqrt(pde_losses))))\n",
    "        fig.colorbar(res)\n",
    "        plt.savefig(plotting_path+'/PDE_Losses.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        #################################################################\n",
    "        #\n",
    "        # BINN prediction\n",
    "        #\n",
    "        #################################################################\n",
    "\n",
    "        u0 = u0.reshape(-1)\n",
    "        ux = ux.reshape(-1)\n",
    "        ut = ut.reshape(-1)\n",
    "        uxx = uxx.reshape(-1)\n",
    "\n",
    "        A = np.concatenate([uxx.reshape(-1, 1), u0.reshape(-1, 1), u0.reshape(-1, 1)**2], axis=1)\n",
    "        B = ut.reshape(-1, 1)\n",
    "        theta = np.dot(np.linalg.pinv(A), B)\n",
    "\n",
    "        D_nn = theta[0]\n",
    "        r_nn = theta[1]\n",
    "        K_nn = -r_nn*(1/theta[2])\n",
    "        D_binn = to_numpy(binn.diffusion.D)\n",
    "        r_binn = to_numpy(binn.growth.r)\n",
    "        K_binn = binn.growth.K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abm_tda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
